---
layout: post
title: >
    #1 Overview: My Plans for this Project
category: project 2
permalink: /projects/F1TSA/:year/:month/:day/:title
date: 31/01/2024
---

## The Overview

Hello! Welcome to my Formula 1 Time Series Analysis project! What I want to do with this first post is give an outline of what I intend to do with the project, the skills I'm looking to develop and a short insight into my first attempt...

So with this project, I'm pretty much new to all aspects of it: First, I'll be using Python in a project for the very first time - which is very exciting; Second, I want to use a new analysis method - Time Series Analysis; and I'm also delving deeper into the history of Formula 1, something I'm also not familiar with. So the premise is to explore the history of Formula 1 and see how major regulation changes in the sport to car design relate to the subsequent performance of both constructor teams and individual drivers. 

For example, "ground effect" was banned in Formula 1 in 1983 and only just recently reintroduced to the sport in 2022 - with this regulation change in 1983, which teams were able to adapt to the new racing environment best and which fell behind? The idea is that we may be able to use Time Series Analysis to help us explore these kinds of questions for any regulation change we want. 

My end goal is to produce a short summary report, starting with a brief exploration of the data before looking at some of the most influential and high-profile regulation changes in the history of Formula 1 and discuss the implications of findings from our time series analysis. 

## Tangent: My "first draft" (APIs are slow...)

So the following posts will be in reference to the actual stages of this project, but I did want to mention that I have written a sort-of "first draft" for this project, which I will no longer be using but wanted to draw attention to. My initial idea for this project was to also collect the data myself by directly writing requests to the Ergast API. However, whilst I have been able to collect data via this method, I'm not sure that using an API in this context is efficient when data from the API can be readily downloaded from Kaggle. Currently, Ergast has a rate limit of 200 requests per hour. Considering that the code I already wrote is making over 1000 requests, collecting the data myself is not worthwhile in my opinion.

However, rather than throw that "first draft" away, I want to share the code I wrote to work directly with the API so you can see my approach and potentially offer advice on what I could do to improve my use of APIs to collect data. I was able to make requests to the API, write nested functions to manipulate the in-coming json code and also was introduced to serialisation and sourcing functions from other .py scripts. I think, whilst limited, all of these experiences have already helped me gain a better understanding of how I can leverage Python to do data analysis work. I do want to make use of this approach to data collection more in the future, but I'll instead look for a use case that doesn't take me 6 hours to run...

With that said, I'll be starting a fresh directory to instead work with .csv files downloaded from Kaggle for this project. But before we start, I think a history lesson is in order! Follow along in the next post where I'll be giving an outline of the history of regulation changes in Formula 1 (or just skip ahead if you're here for the analysis!)

Thank you :)
